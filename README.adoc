= Comparing Distributed Programming in Rust and Go

== Overview

The purpose of this project is to compare the programming languages Rust and Go regarding their capabilities and characteristics for distributed programming.

First, we will take a look at the general characteristic of Rust and Go. 
If you are interested in more technical details head over to <<Distributed Programming in Rust and Go>> where we will implement a gRPC Server and Client in Rust and Go.

== General Aspects of Rust and Go

Rust and Go are in many ways quite similar but they do have some striking differences.
Regarding syntax, both languages are inspired by C and C++ and simple code snippets can sometimes look almost identical:

[source,rust]
----
fn main(){
   println!("This says Hello World in Rust!");
}
----

[source,go]
----
func main() { 
    fmt.Println("This says Hello World in Go!") 
} 
----

Both languages have a strong, static type system that supports type inference.
When it comes to programming paradigms, both languages follow a mixed paradigm approach that is mostly imperative.
Rust and Go are both compiled languages with a compiler that supports cross compilation.
The most important technical difference between the two is that Go has a garbage collector whereas Rust does not.
This of course means that Rust offers better memory efficiency overall but it also adds additional complexity when coding in Rust as you have deal with Rust's https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html[ownership system].

|===
|Language |Rust |Go 

| Garbage collector
| No GC
| Has GC

| Type system
| static
| static

| Cross compilation
| supported
| supported

|===

== Distributed Programming in Rust and Go 

One thing that is pretty much inevitable when it comes to distributed systems programming is to have some form of messaging solution so that individual computing nodes can exchange serialized data.

A widely used solution for this is Google's https://grpc.io/[gRPC] so let's take a look at gRPC implementations for Go and Rust. For demonstration purposes, i built a small noticeboard service with a server that hosts notes which the client can query by title or author. You can find the code in the `/grpc-example` directory.
The `/grpc-example/proto` directory contains the protobuf definition file for the gRPC service.
Since both implementations of the service use the same protobuf definition, the respective client and server should be able to communicate with each other interchangeably. 
That means you can run the Rust client with the Go server and vice versa.

Go of course has an https://github.com/grpc/grpc-go[official implementation of gRPC] so that's what i used.
For Rust i had to look around a bit to find a suitable implementation.
Luckily, Rust has a very convenient package registry with https://www.crates.io[crates.io].

On crates.io you can find multiple crates (Rust's version of packages/libraries) that offer gRPC implementations. The most promising one at the time seems to be https://crates.io/crates/tonic[tonic] because it has the highest number of all-time and recent downloads. This is the one i decided to use.

=== Setup - Protobuf Code Generation

What's nice about working with Protobuf is that the compiler `protoc` can generate code for different languages based on your service definition that helps implement the service in the respective language.
This way you don't have to worry about things like serializing your data structures as Protobuf messages.

==== Code Generation in Rust

Tonic offers the additional package `tonic-build` which can handle the code generation automatically.
This way you don't need to invoke `protoc` seperately and can just use Rust's own build tool Cargo.
To generate Rust code for implementing the service all we need to do is add `tonic-build` as a build dependency in the `Cargo.toml` configuration file:

[source,rust]
----
[build-dependencies]
tonic-build = "0.3"
----

and an additional file called `build.rs` in the root directory with the following content:
[source,rust]
----
fn main() {
    tonic_build::compile_protos("../proto/notes.proto") // make sure to provide the correct path
        .unwrap_or_else(|e| panic!("Failed to compile protos {:?}", e));
}
----

Now we can run `cargo build` in the `/grpc-example/rust-grpc` directory to compile our code.

For Go:
compile protobuf `protoc --proto_path=../proto --go_out=plugins=grpc:build/gen ../proto/notes.proto`

Some notes:

- generating the code from protobuf definitions is actually easier with rust and tonic because you only one command whereas with go you have to invoke protoc seperately

== Asynchronous Programming

== Available Frameworks  

When it comes to building large distributed systems that are suited for production use in an enterprise environment, most of the time you probably don't want to build everything from scratch. So it makes sense to choose a framework or platform to build upon. Ideally, this should be one that is already being used by many other people and has turned out to be tried and true.

=== Frameworks for Rust

[cols="1,9a,1"]
|===
|Name |Description |Stars on GitHubfootnoteref:[1,as of 2021-01-09]

|https://github.com/actix/actix[Actix]
|
- framework for using an https://en.wikipedia.org/wiki/Actor_model[actor model] in Rust
- offer asynchronous message handling via futures
|5.9k

|https://github.com/tokio-rs/tokio[Tokio]
|
- asynchronous runtime for rust
- promises very high performance and scalability
|10.7k

|https://github.com/ballista-compute/ballista[Ballista]
|
- also offers support for Python and Java as well as connectors for JDBC and Spark
- promises high memory efficiency, superior to Spark's
- based on the memory model of https://arrow.apache.org/[Apache Arrow]
|971

|https://github.com/constellation-rs/amadeus[Amadeus]
|
- distributed data processing using streams
- supports various data formats and database systems for importing data (e.g. CSV, JSON, S3, Postgres)
- supposed to offer a particularly easy approach to distributed data processing
|213

|https://github.com/fede1024/rust-rdkafka[rust-rdkafka]
|
- asynchronous client for https://kafka.apache.org/[Apache Kafka]
- wrapper for https://github.com/edenhill/librdkafka[librdkafka] (Kafka client for C/C++)
|595

|===

=== Frameworks for Go

[cols="1,9a,1"]
|===
|Name |Description |Stars on GitHubfootnoteref:[1,as of 2021-01-09]

|https://github.com/asim/go-micro[go-micro]
|
- broadly diversified framework for distributed systems development offering many different features
- supports RPC based communication
- promises to provide sane defaults to enable quick productivity
|15.2k

|https://github.com/emitter-io/emitter[Emitter]
|
- distributed publish/subscribe platform using MQTT
- Fulfils the high-availability and partition tolerance criteria of the CAP theorem
|2.7k

|https://github.com/lni/dragonboat[Dragonboat]
| 
- high performance multi-group Raft consensus library
- claims to be easy to use and handle all technical difficulties of the Raft protocol
|3.4k

|https://github.com/chrislusf/glow[glow]
|
- library for scalable parallel and distributed data processing
- functional aproach using map reduce
|2.9k

|https://github.com/chrislusf/gleam[gleam]
|
- high performance and efficient distributed execution system
- also using map reduce funcionality
|2.7k

|===

== Additional Thoughts

One central aspect of Rust's philosophy is its focus on performance.
Although better low-level performance is in general a good thing, this particular advantage of Rust might not be as useful when it comes to building distributed systems. Since the performance of a distributed system as a whole tends to be constrained more by network latency than by the execution time of individual tasks.

On the other hand, the fact that Rust offers very good memory efficiency means that it could be suited very well for distributed systems that keep a lot of data in memory at a time. For example, the authors of the Ballista framework claim that:

__"The combination of Rust and Arrow provides excellent memory efficiency and memory usage can be 5x - 10x lower than Apache Spark in some cases"__footnote:[https://github.com/ballista-compute/ballista#how-does-this-compare-to-apache-spark]

== Summary

